---
title: "Edinbr: Text Mining with R"
author: "Colin Gillespie"
date: 2018-02-24
output: html_document
image: "img/2018/tidytext_edinbr.jpg"
draft: false
slug: "tidytext_edinbr_2018"
tags: [r,tidyverse,tidytext,edinbr]
editor_options: 
  chunk_output_type: console
---

```{r, echo=FALSE, out.width="400", fig.align="center"}
#knitr::include_graphics("/img/2018/tidytext_edinbr.jpg")
```

During a very quick tour of Edinburgh (and in particular some distilleries), 
[Dave Robinson](http://www.twitter.com/drob) (Tidytext fame), was able to 
drop by the [Edinburgh R](http://edinbr.org) meet-up group to give a very 
neat talk on tidy text. The first part of the talk set the scene

  * What does does text mean?
  * Why make text tidy?
  * What sort of problems can you solve.

This was a very neat overview of the topic and gave persuasive arguments 
around the idea of using a data frame for manipulating text. Most of the details are in Julie's and his 
book on [Text Mining with R](https://www.tidytextmining.com/).

Personally I found the second part of his talk the best, where
Dave did an "off the cuff" demonstration of a tidy text analysis of the "Scottish play" (see  [Blackadder](https://www.youtube.com/watch?v=h--HR7PWfp0) for details on the "Scottish play").

After loading a few packages

```{r, message = FALSE}
library("gutenbergr")
library("tidyverse")
library("tidytext")
library("zoo")
```

He downloaded the "Scottish Play" via the [Gutenbergr](CRAN) package
```{r, message = FALSE, cache=TRUE}
macbeth = gutenberg_works(title == "Macbeth") %>%
  gutenberg_download()
```
Then proceeded to generate a bar chart of the top $10$ words (excluding stop words
such as _and_, _to_), via 
```{r, fig.align="center"}
macbeth %>%
  unnest_tokens(word, text) %>% # Make text tidy
  count(word, sort = TRUE) %>% # Count occurances
  anti_join(stop_words, by = "word") %>% # Remove stop words
  head(10) %>% # Select top 10
  ggplot(aes(word, n)) + # Plot
  geom_col() 
```

The two key parts of this code are

 * `unnest_tokens()` - used to tidy the text
 * `anti_join()` - remove any `stop_words`.

Since this analysis was "off the cuff", Dave noticed that
we could easily extract the speaker. This is clearly something you would
want to store and can be achieved via a some `mutate()` magic
```{r}
speaker_words = macbeth %>%
  mutate(is_speaker = str_detect(text, "^[A-Z ]+\\.$"), # Detect capital letters
         speaker = ifelse(is_speaker, text, NA),
         speaker = na.locf(speaker, na.rm = FALSE))
```
The `str_detect()` uses a simple regular expression to determine if the text are
capital letters (theyby indicating a scene). Any expression of length zero is replaced,
by a missing value `NA`. Before finishing with the __zoo__ `na.locf()` function
to carry the last observation forward, thereby filling the blanks.

The resulting tibble is then cleaned using
```{r}
speaker_words = speaker_words %>%
  filter(!is_speaker, !is.na(speaker)) %>%
  select(-is_speaker, -gutenberg_id) %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words, by = "word") 
```
A further bit of analysis
```{r}
speaker_words %>%
  count(speaker, word, sort = TRUE) %>%
  bind_tf_idf(word, speaker, n) %>%
  arrange(desc(tf_idf)) %>%
  filter(n >= 5)
```

In my opinion, the best part of the night was the lively question and answer session. 
The questions were on numerous topics (I didn't write them down sorry!), that 
Dave handled with ease, usually with another off-the-cuff demo.

#### Further Links

  * [Edinburgh R user group](http://edinbr.org/)
  * Dave Robinson: [twitter](https://twitter.com/drob), [blog](http://varianceexplained.org/about/)
  * [Blackadder](https://www.youtube.com/watch?v=h--HR7PWfp0) discusses the 
  Scottish play
  
  
  
  



