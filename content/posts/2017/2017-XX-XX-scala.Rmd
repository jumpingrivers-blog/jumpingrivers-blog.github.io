---
title: "Scala for statistical computing and data science"
slug: "aboutscala"
date: 2017-10-14
output: html_document
excerpt: "Why use Scala"
tags: [scala]
#image: "img/2017/stan-density.png"
draft: true
---

[Scala](https://www.scala-lang.org/) is a fast, efficient programming language with excellent built-in support for parallelism and concurrency. It is a strongly-typed functional language with a sophisticated type system, including type-inference, enabling the writing of elegant, concise, expressive code. Programs written in Scala are typically as short, or shorter than equivalent programs written in dynamic languages such as R or Python, but are safer, more modular, and execute an order-of-magnitude faster (even without parallelism). They also run on any platform with a JVM.

Scala's built-in support for concurrency and parallelism make it easy to make algorithms parallel, often with trivial modifications of serial code. Many algorithms used in statistical computing, machine learning, and data science can benefit from parallelisation, giving further speed-ups on modern multi-core machines.

Apache Spark is a Scala library for robust scalable, distributed computing, machine learning, and big data analytics. Using Spark with Scala trivially enables the distributed processing and rapid analysis of huge datasets on computing clusters, using straightforward code which abstracts away most of the technical details of precisely how to perform computations in a parallel, distributed manner. The in-memory approach used by Spark makes it ideal for statistical computing and machine learning applications requiring many passes over the data.

