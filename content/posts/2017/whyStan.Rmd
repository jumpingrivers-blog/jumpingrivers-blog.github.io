---
title: "Why use Stan"
slug: "whystan"
date: 2017-10-14
excerpt: "Reasons why you would want to use stan"
tags: [stan]
image: "img/2017/stan-density.png"
draft: true
---

> Stan is freedom-respecting, open-source software for facilitating statistical inference at 
> the frontiers of applied statistics.

Or at least that's what there [website](http://mc-stan.org/) tells us ;)

Over the last year we've been running Stan [training courses](https://www.jumpingrivers.com/courses/13_introductions-to-bayesian-inference-using-rstan), 
and we often get the question about why would some le


##### I normally use preprogrammed software to perform Bayesian inference for specific classes of models?

Stan is a general purpose modelling language that allows you to fit a large class of models. By learning one language, you have much greater flexibility in specifying your model, and avoid having to get to grips with different software for different models.

##### I normally use BUGS or JAGS to fit my Bayesian model

  * BUGS and JAGS are based on Gibbs sampling, whilst Stan uses Hamiltonian Monte Carlo (HMC) to generate samples from the posterior distribution. HMC is often more efficient which means Stan can be faster for complex models and scales better for large data sets.
  * In many ways, the Stan modelling language is more flexible than BUGS or JAGS, allowing you to fit a less restricted class of models.

##### I normally write my own code to fit my Bayesian model

  * Writing your own sampler, especially one that is efficient, is laborious. Writing the programme in Stan is generally much faster.
  * A huge amount of effort, from a large development team, has been devoted to optimising the performance of Stan. It often runs much faster than handwritten code.
  * To provide a point of comparison, to help debug your handwritten code.

---

Interesed in learning Stan? We run public and on-site Stan [training courses](https://www.jumpingrivers.com/courses/13_introductions-to-bayesian-inference-using-rstan). 


```{r density,echo=FALSE, cache=TRUE}
set.seed(1)
N = 500
y = lapply(1:N, function(i) {
  x = rlnorm(50)
  density(x, from = -1.5, to = 8, n = 500)$y
}
)

x = seq(-3, 8, length.out = 500)

y_mean = colSums(Reduce(rbind, y))
y_mean = y_mean/length(y)

col  = rgb(85,130,169, alpha=255, maxColorValue=255)
plot(x, y_mean, type="l", ylim=c(0, 1), 
     lwd = 4, col=col, axes = FALSE, 
     ylab = NA, xlab = NA)

col  = rgb(85,130,169, alpha=10, maxColorValue=255)
for(i in 1:length(y)) {
  lines(x, y[[i]], col= col)
}
```
 
